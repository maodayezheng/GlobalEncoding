{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 0. Notebook prep"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from matplotlib import pyplot as plt\n",
    "import os \n",
    "ae_ae_loss = np.load(\"visualization/ae_ae_loss.npy\")\n",
    "ae_ae_loss = np.mean(ae_ae_loss.reshape(1000, 100), axis=-1)\n",
    "ae_rnn_loss = np.load(\"visualization/ae_rnn_loss.npy\")\n",
    "ae_rnn_loss = np.mean(ae_rnn_loss.reshape(1000, 100), axis=-1)\n",
    "bow_ae_loss = np.load(\"visualization/bow_ae_loss.npy\")\n",
    "bow_ae_loss = np.mean(bow_ae_loss.reshape(1000, 100), axis=-1)\n",
    "bow_rnn_loss = np.load(\"visualization/bow_rnn_loss.npy\")\n",
    "bow_rnn_loss = np.mean(bow_rnn_loss.reshape(1000, 100), axis=-1)\n",
    "rnn_loss = np.load(\"visualization/rnn_loss.npy\")\n",
    "rnn_loss = np.mean(rnn_loss.reshape(1000, 100), axis=-1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 1. Recurrent Neural Language Model \n",
    "\n",
    "Given the one-hot embeddings $\\{\\boldsymbol{x}_{1}, \\boldsymbol{x}_{2}, ... , \\boldsymbol{x}_{T}\\}$ of a specific sentence, the RNNLM can assign the probability to the sentence as follow\n",
    "\\begin{equation}\n",
    "\t\\boldsymbol{h}_{t} = f(\\boldsymbol{E}_{in}\\boldsymbol{x}_{t},  \\boldsymbol{h}_{t-1})\n",
    "\\end{equation}\n",
    "\\begin{equation}\n",
    "\t\\boldsymbol{o}_{t} = \\boldsymbol{W}_{o}\\boldsymbol{h}_{t} + \\boldsymbol{b}_{o}\n",
    "\\end{equation}\n",
    "\\begin{equation}\n",
    "\ty_{t} = \\frac{\\exp(\\boldsymbol{o}_{t}^{T}\\boldsymbol{E}_{out}\\boldsymbol{x}_{t+1})}{\\sum_{\\boldsymbol{x}_{k} \\in \\boldsymbol{V}}\\exp(\\boldsymbol{o}_{t}^{T}\\boldsymbol{E}_{out}\\boldsymbol{x}_{k})}\n",
    "\\end{equation}\n",
    "where the function $f(\\cdot)$ is a single step RNN operation and $\\boldsymbol{V}$ is the collection of one-hot vectors for full vocabulary. \n",
    "Then probability given by the recurrent network to the input sequence $\\{\\boldsymbol{x}_{1}, \\boldsymbol{x}_{2}, ... , \\boldsymbol{x}_{T}\\}$ is \n",
    "\\begin{equation}\n",
    "\tp(\\boldsymbol{x}_{1}, \\boldsymbol{x}_{2}, ... , \\boldsymbol{x}_{T}) = \\prod_{t=1}^{T} p(\\boldsymbol{x}_{t+1}|y_{t})\n",
    "\\end{equation}\n",
    "and the sequence loss $\\mathcal{L}_{rnn}$ used to train the network is the negative logarithm of $p(\\boldsymbol{x}_{1}, \\boldsymbol{x}_{2}, ... , \\boldsymbol{x}_{T})$\n",
    "\\begin{equation}\n",
    "\t\\mathcal{L}^{rnn} = -\\sum_{t=1}^{T}\\log p(\\boldsymbol{x}_{t+1}|y_{t})\n",
    "\\end{equation}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 2. Recurrent Neural Language Model with Autoencoder\n",
    "\n",
    "The RNNLM discussed above can combine with an autoencoder by modified the equation (2) as \n",
    "\\begin{equation}\n",
    "\\boldsymbol{o}_{t} = \\boldsymbol{W}_{o}\\boldsymbol{h}_{t} +\\boldsymbol{W}_{z}\\boldsymbol{z} +  \\boldsymbol{b}_{o}\n",
    "\\end{equation}\n",
    "where $\\boldsymbol{z}$ is the dense representation of $\\{\\boldsymbol{x}_{1}, \\boldsymbol{x}_{2}, ... , \\boldsymbol{x}_{T}\\}$ encoded by autoencoder as follow\n",
    "\\begin{equation}\n",
    "\\boldsymbol{g}_{in} = \\text{Relu}(\\boldsymbol{W}_{in}\\begin{bmatrix}\n",
    "\\boldsymbol{E}_{in}\\boldsymbol{x}_{1}\\\\\n",
    ".\\\\\n",
    ".\\\\\n",
    ".\\\\\n",
    "\\boldsymbol{E}_{in}\\boldsymbol{x}_{T}\\\\\n",
    "\\end{bmatrix} + \\boldsymbol{b}_{in})\n",
    "\\end{equation}\n",
    "\\begin{equation}\n",
    "\t\\boldsymbol{z} = \\text{Relu}(\\boldsymbol{W}_{g}\\boldsymbol{g}_{in}+ \\boldsymbol{b}_{g})\n",
    "\\end{equation}\n",
    "\\begin{equation}\n",
    "\t\\boldsymbol{g}_{out} = \\text{Relu}(\\boldsymbol{W}_{out}\\boldsymbol{z} + \\boldsymbol{b}_{out})\n",
    "\\end{equation}\n",
    "The output of autoencode is \n",
    "\\begin{equation}\n",
    "\ty_{t}^{ae} = \\frac{\\exp(\\boldsymbol{g}_{out}^{T}\\boldsymbol{E}_{out}\\boldsymbol{x}_{t})}{\\sum_{\\boldsymbol{x}_{k}\\in \\boldsymbol{V}}\\exp(\\boldsymbol{g}_{out}^{T}\\boldsymbol{E}_{out}\\boldsymbol{x}_{k})}\n",
    "\\end{equation}\n",
    "The probability given by the autoencoder to the input sequence $\\{\\boldsymbol{x}_{1}, \\boldsymbol{x}_{2}, ... , \\boldsymbol{x}_{T}\\}$ is \n",
    "\\begin{equation}\n",
    "\tp(\\boldsymbol{x}_{1}, \\boldsymbol{x}_{2}, ... , \\boldsymbol{x}_{T}) = \\prod_{t=1}^{T} p(\\boldsymbol{x}_{t}|y_{t}^{ae})\n",
    "\\end{equation}\n",
    "and the loss $\\mathcal{L}^{ae}$ defined on the autoencoder is \n",
    "\\begin{equation}\n",
    "\t\\mathcal{L}^{ae} = -\\sum_{t=1}^{T}\\log p(\\boldsymbol{x}_{t}|y_{t}^{ae})\n",
    "\\end{equation}\n",
    "then the total loss of this joint model is \n",
    "\\begin{equation}\n",
    "\t\\mathcal{L} = (1.0 - \\alpha)\\mathcal{L}^{ae} + \\alpha\\mathcal{L}^{rnn}\n",
    "\\end{equation}\n",
    "where $\\alpha$ is a hyper-parameter."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 3. Experiment Settings \n",
    "We selected 300k sentences of 20 words length from One Billion Sentences Evaluation dataset and keep 1k of them as testing examples. \n",
    "And we keep 40,000 most frequent words in our vocabulary and replace other words with ``$<\\text{unk}>$'' token. \n",
    "When building our model we use gated recurrent unit (GRU) as the cell for our recurrent networks.\n",
    "We train our model for 10 epoches on the selected sentences. \n",
    "Note that the AE + RNNLM model is tried three times with $\\alpha = \\{0.1, 0.5, 0.9\\}$.\n",
    "The table below gives the detail about the model's dimensionality.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "|        |        Vocabulary Size    | Embedding dimension | Hidden (RNN) | Hidden (AE) | \n",
    "| -------| :-------------------------:| :------------------:|:------------:| :-----------:| \n",
    "| RNN      | 8192 |  256| 512 | -| \n",
    "| AE + RNN      | 8192     |   256 | 512 | 512| \n",
    "| BW + RNN      | 8192     |   256 | 512 | 512| "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 4. Comparison \n",
    "## 4.1 Loss\n",
    "The figures below show the training loss between BW + RNN and AE + RNNLM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'plt' is not defined",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-1-b72c1c92986c>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mplt\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfigure\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      2\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0;31m# linear\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0mplt\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msubplot\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m221\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0mplt\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mplot\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mae_rnn_loss\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlabel\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m\"ae + rnn\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mNameError\u001b[0m: name 'plt' is not defined"
     ],
     "output_type": "error"
    }
   ],
   "source": [
    "plt.figure(1)\n",
    "\n",
    "# linear\n",
    "plt.subplot(221)\n",
    "plt.plot(ae_rnn_loss, label=\"ae + rnn\")\n",
    "plt.plot(bow_rnn_loss, label=\"bw + rnn\")\n",
    "plt.yscale('linear')\n",
    "plt.title('rnn loss ')\n",
    "plt.legend()\n",
    "plt.grid(True)\n",
    "\n",
    "\n",
    "# log\n",
    "plt.subplot(222)\n",
    "plt.plot(ae_ae_loss, label=\"ae + rnn\")\n",
    "plt.plot(bow_ae_loss, label=\"bw + rnn\")\n",
    "plt.yscale('linear')\n",
    "plt.title('ae loss')\n",
    "plt.legend()\n",
    "plt.grid(True)\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4.2 Sample From RNN\n",
    "The setences below are samples drawn from standard RNNLM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1th RNN Sample :  a little be already guy on the current pattern , entering london , laugh .\n",
      "\n",
      "2th RNN Sample :  uk major winner within 1999 to the agency six crash in â‚¬ district seas .\n",
      "\n",
      "3th RNN Sample :  do i buy the system to be having an competitive enemy wins the system .\n",
      "\n",
      "4th RNN Sample :  hollywood were injured to the content at paris 's african major killing metal windows .\n",
      "\n",
      "5th RNN Sample :  roman will betting since loans to flood more present legendary and each month support .\n",
      "\n",
      "6th RNN Sample :  jail , from many areas now were set away to their stomach handling dame .\n",
      "\n",
      "7th RNN Sample :  china officials and serena alike were gaining year ; the crowded hotel and faces .\n",
      "\n",
      "8th RNN Sample :  murphy has announced how two times indicator are expected to secure down discomfort race .\n",
      "\n",
      "9th RNN Sample :  it won some respected may the new government council , british news here said .\n",
      "\n",
      "10th RNN Sample :  i saw it keys out of a long objective and department ! has arrived .\n",
      "\n"
     ]
    }
   ],
   "source": [
    "with open(\"visualization/rnn_sample.txt\", \"r\") as samples:\n",
    "    for line in samples:\n",
    "        print(line)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4.3 Sample From AE+RNN and BW+RNN"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The sentences below are max-likelihood sentences find based on 100 samples "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "origin : \" He is thrilled not to have to go shopping , \" she said .\n",
      "\n",
      "  ae   :  `` i definitely not be like , because said , a fund 's identity .\n",
      "\n",
      "  bw   :  `` he was not <unk> to <unk> insurance to `` he go to `` ``\n",
      "\n",
      "origin : \" Vigilance should nevertheless remain high during this period , \" the center said .\n",
      "\n",
      "  ae   :  `` i knew not be soul , soul 's well , `` <unk> said .\n",
      "\n",
      "  bw   :  `` mr. <unk> <unk> said money will release around inflation , the publicity said .\n",
      "\n",
      "origin : \" Chris has put himself in such a jam financially , \" Lewis said .\n",
      "\n",
      "  ae   :  `` i 'm be manager , `` will said , or obama 's given .\n",
      "\n",
      "  bw   :  `` i don 't think i be liked , `` <unk> has the <unk> .\n",
      "\n",
      "origin : \" Our economy has dealt very well with this situation , \" Velasco said .\n",
      "\n",
      "  ae   :  `` the president was thought to be , `` he was <unk> was <unk> .\n",
      "\n",
      "  bw   :  `` i didn 't turned , `` i buy <unk> the petit will <unk> .\n",
      "\n",
      "origin : \" This medication is far safer , \" Camilleri said in a telephone interview .\n",
      "\n",
      "  ae   :  `` i match too reporters 's it will be , `` , did said .\n",
      "\n",
      "  bw   :  `` he was going to <unk> <unk> <unk> <unk> `` <unk> <unk> to <unk> .\n",
      "\n",
      "origin : \" I would be totally , completely stunned , \" one staff member said .\n",
      "\n",
      "  ae   :  `` the case was not car , when the <unk> is also was <unk> .\n",
      "\n",
      "  bw   :  `` i don 't just buying , david it would <unk> the <unk> talent .\n",
      "\n",
      "origin : \" Greenpeace is disappointed especially by U.S. and EU authorities , \" said Schoppink .\n",
      "\n",
      "  ae   :  `` the soldier is obviously hillary , `` he was <unk> 's <unk> <unk> .\n",
      "\n",
      "  bw   :  `` i continued there company 's dr , she <unk> wasn 't going anything .\n",
      "\n",
      "origin : \" They are under suspension pending our investigation , \" Galbreth said in statement .\n",
      "\n",
      "  ae   :  `` i can be happy , crowley a right , `` he said said .\n",
      "\n",
      "  bw   :  `` i car wasn 't enough , `` she 's <unk> has a courtroom .\n",
      "\n",
      "origin : \" I wouldn 't use it , \" she said , giggling uncomfortably .\n",
      "\n",
      "  ae   :  `` i think not be a system , there was not be a meals .\n",
      "\n",
      "  bw   :  `` i am passed 's want , `` she ads <unk> <unk> sex said .\n",
      "\n",
      "origin : \" The atmosphere is amazing -- it 's buzzing , \" she said .\n",
      "  ae   :  `` i added 's memories will be , `` even police percent to office .\n",
      "\n",
      "  bw   :  `` i 'm doesn 't know mr. everything 's <unk> , `` no studio .\n",
      "\n"
     ]
    }
   ],
   "source": [
    "prefix = \"quotes\"\n",
    "file_type = \".txt\"\n",
    "orign = prefix + file_type\n",
    "ae_sample = \"ae_\" + prefix + file_type\n",
    "bw_sample = \"bow_\" + prefix + file_type\n",
    "with open(\"visualization/\" + orign, \"r\") as doc1, open(\"visualization/\" + ae_sample, \"r\") as doc2, open(\"visualization/\" + bw_sample, \"r\") as doc3:\n",
    "    \n",
    "    for line in doc1:\n",
    "        print(\"origin : \" + line)\n",
    "        print(\"  ae   : \" + doc2.readline())\n",
    "        print(\"  bw   : \" + doc3.readline())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "221B"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 5. Next steps"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "To be discussed "
   ]
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python [conda root]",
   "language": "python",
   "name": "conda-root-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3.0
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}